---
title: "About Me"
sitemap: false
permalink: /
---

<link href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css" rel="stylesheet">
<link rel="stylesheet" href="../assets/style.css">

I completed my BSc in Computer Science & Engineering from Rajshahi University of Engineering & Technology. I am currently working as a Machine Learning Engineer at Euclido.Inc.- a Canada-based Ed-tech start-up. 

My research interests broadly lie in the intersection of natural language processing and machine learning. I am currently interested in language models and agents; in particular, I aim to study the downstream effects of **pretraining data** and methods to improve the capabilities and efficiency of **reasoning** models. 

Below are a few questions I am interested in:

<p class="header">Data:</p>
<ul>
<li>How does pretraining data influence language models as sources of knowledge? <a href="https://arxiv.org/abs/2403.12958">Dated Data</a></li>
<li>Can we attribute content generated by models back to their pretraining corpus?</li>
<li>How do we best correct misalignments arising from knowledge conflicts in models' pretraining data?</li>
</ul>
	
<p class="header">Reasoning:</p>
<ul>
<li>Can we make reasoning models more efficient by shifting away from a discrete token space and perform reasoning in continuous latent space? <a href="https://arxiv.org/abs/2412.13171">Compressed Chain of Thought</a></li>
<li>How much better would reasoning models be if trained with process rewards rather than just outcome rewards?</li>
<li>How can we construct environments with verifiable rewards and/or induce structure into reasoning chains to make models more capabale and efficient?</li>
</ul>

I would love to discuss my research and any opportunities! Feel free to email me at *rakib.ruet.cs@gmail.com*

Outside of work, I play <a href="https://fantasy.premierleague.com/entry/1519949/event/1">Fantasy Premier League</a>.

Slices of life
---
 
<table>
	<tr>
		<td width="15%">May 2025</td><td>Paper Rejected in ACL 2025ðŸ˜­!</td>
  	</tr>
	<tr>
		<td width="15%">Apr 2025</td><td>Contributed to <a href="https://github.com/aritraghsh09/pdflatex_bengali">pdflatex_bengali</a> for Bangla Transliteration with <a href="https://medium.com/@rakib1703115/writing-bangla-in-pdflatex-now-made-easy-53e43ab6f172">Bangtex</a> </td>
  	</tr>
	<tr>
		<td width="15%">Nov 2024</td><td>Created a python package <a href="https://pypi.org/project/DetectVideoShotLength/">DetectVideoShotLength</a> to analyze movie scene lengths.</td>
  	</tr>
<!-- 	<tr>
		<td width="15%">Oct 2024</td><td>Attended CoLM 2024 and presented Dated Data <b>(Outstanding Paper Award, 0.4% <i class="bi bi-trophy"></i>)</b></td>
	</tr>
	<tr>
		<td width="15%">Jul 2024</td><td>Dated Data accepted to CoLM 2024!</td>
	</tr> -->
	<tr>
		<td width="15%">Mar 2024</td><td>New preprint, Dated Data, is out! <a href="https://arxiv.org/abs/2403.12958">[paper]</a> <a href="https://x.com/jeff_cheng_77/status/1772355368649187669">[tweets]</a> </td>
	</tr>
</table>
